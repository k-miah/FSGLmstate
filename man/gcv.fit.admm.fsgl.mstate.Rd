% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gcv.fit.admm.fsgl.mstate.R
\name{gcv.fit.admm.fsgl.mstate}
\alias{gcv.fit.admm.fsgl.mstate}
\title{gcv.fit.admm.fsgl.mstate}
\usage{
gcv.fit.admm.fsgl.mstate(
  lambda.grid,
  X,
  d,
  penalized = NULL,
  unpenalized = NULL,
  K,
  standardize = TRUE,
  nl,
  nf,
  ng,
  groupsizes,
  penalty.factor = 1,
  alpha.grid = seq(0, 1, by = 0.25),
  gamma.grid = seq(0, 1, by = 0.25),
  rho = 1,
  beta.init = NULL,
  step_size = 0.01,
  est_tol = 1e-06,
  eps_rel = 0.01,
  eps_abs = 1e-04,
  max_iter = 100,
  n.cores = 1
)
}
\arguments{
\item{lambda.grid}{\link{vector}: Candidate vector for overall regularization parameter in \verb{\[0,1\]}}

\item{X}{\link{data frame}: Regression matrix of dimension n x p (=P*Q) with transition-specific covariates}

\item{d}{\link{data frame}: Data set with variables Tstart, Tstop, trans and status (long format data)}

\item{penalized}{\link{data frame}: Regression matrix of dimension n x p (=P*Q) with covariates that should be penalized}

\item{unpenalized}{\link{data frame}: Regression matrix of dimension n x p (=P*Q) with additional covariates that should remain unpenalized}

\item{K}{\link{matrix}: Penalty matrix of dimension M x p (=P*Q)}

\item{standardize}{\link{logic}: Standardization of design matrix X (TRUE: columns divided by standard deviation)}

\item{nl}{\link{numeric}: Number of rows of K that encode the lasso penalty (If lasso penalty is applied to all coefficients: p)}

\item{nf}{\link{numeric}: Number of rows of K that encode the fused penalty}

\item{ng}{\link{numeric}: Number of groups for the group penalty}

\item{groupsizes}{\link{vector}: Vector of length ngroups that gives the size of each group in the order they appear in the K matrix (Sum should equal ng)}

\item{penalty.factor}{\link{vector}: Individual penalty scaling factor (default: 1)}

\item{alpha.grid}{\link{vector}: Tuning parameter in \verb{\[0,1\]}; controls degree of group (alpha = 0) vs lasso (alpha=1) penalty}

\item{gamma.grid}{\link{vector}: Tuning parameter in \verb{\[0,1\]}; controls degree of lasso (gamma=1) vs fused (gamma=0) penalty}

\item{rho}{\link{numeric}: Augmented Lagrangian parameter (ADMM step size; default: 1)}

\item{beta.init}{\link{vector}: Initial value of beta (default: 0)}

\item{step_size}{\link{numeric}: Gradient ascent step size in (0,1) (default: .01)}

\item{est_tol}{\link{numeric}: Tolerance of stopping criterion (partial log-likelihood) for beta estimation (default: 1e-6)}

\item{eps_rel}{\link{numeric}: Relative tolerance for ADMM stopping criterion (default: .01)}

\item{eps_abs}{\link{numeric}: Absolute tolerance for ADMM stopping criterion (default: .0001)}

\item{max_iter}{\link{numeric}: Maximum number of iterations (default: 1000)}

\item{n.cores}{\link{numeric}: Number of cores for parallel computing}
}
\value{
res.min.gcv \link{list}: Beta estimation for optimal lambda (i.e. minimal GCV)
}
\description{
R-function utilizing ADMM to fit FSGL-penalized multi-state models for beta estimation for optimal lambda with minimal general cross-validation statistic (GCV) via grid search
}
